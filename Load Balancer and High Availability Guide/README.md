## So what is Load balancing ?

Load balancing refers to efficiently distributing incoming network traffic across a group of backend servers, also known as a server farm or server pool 

A load balancer acts as the ‚Äútraffic cop‚Äù üëÆ sitting in front of your servers ( also know as frontend ) and routing client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it.

In this manner, a load balancer performs the following functions:

- Distributes client requests or network load efficiently across multiple servers
- Ensures high availability and reliability by sending requests only to servers that are online
- Provides the flexibility to add or subtract servers as demand dictates

Load Balancing Algorithms
Different load balancing algorithms provide different benefits; the choice of load balancing method depends on your needs:

- Round Robin ‚Äì Requests are distributed across the group of servers sequentially.
Least Connections ‚Äì A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections.
- Least Time ‚Äì Sends requests to the server selected by a formula that combines the
fastest response time and fewest active connections. Exclusive to NGINX Plus.
- Hash ‚Äì Distributes requests based on a key you define, such as the client IP address or
the request URL. NGINX Plus can optionally apply a consistent hash to minimize redistribution
of loads if the set of upstream servers changes.
- IP Hash ‚Äì The IP address of the client is used to determine which server receives the request.
-Random with Two Choices ‚Äì Picks two servers at random and sends the request to the
one that is selected by then applying the Least Connections algorithm (or for NGINX Plus
the Least Time algorithm, if so configured).

For this you will need at least 4 server's, where

- haproxy01
- haproxy02
- webserver01
- webser02

The first two will guarantee that your service can run smootly, 
